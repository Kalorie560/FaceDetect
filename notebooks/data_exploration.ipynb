{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 顔特徴点検出データの探索 / Facial Keypoints Data Exploration\n",
    "\n",
    "このノートブックでは、Kaggle顔特徴点検出データセットの探索的データ分析を行います。\n",
    "\n",
    "This notebook performs exploratory data analysis on the Kaggle facial keypoints detection dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "from data.preprocessing import DataPreprocessor\n",
    "from utils.visualization import (\n",
    "    plot_keypoints_on_image, \n",
    "    visualize_data_distribution,\n",
    "    KEYPOINT_NAMES\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データ読み込み / Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "# Please ensure you have downloaded the Kaggle data\n",
    "data_path = \"../training.csv\"  # Adjust path as needed\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"データが正常に読み込まれました / Data loaded successfully\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"データファイルが見つかりません / Data file not found\")\n",
    "    print(\"Please download the Kaggle facial keypoints detection data\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データ基本情報 / Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Basic information\n",
    "    print(\"データセット基本情報 / Dataset Basic Information\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"サンプル数 / Number of samples: {len(df)}\")\n",
    "    print(f\"列数 / Number of columns: {len(df.columns)}\")\n",
    "    print(f\"画像列 / Image column: {'Image' in df.columns}\")\n",
    "    \n",
    "    # Keypoint columns\n",
    "    keypoint_cols = [col for col in df.columns if col != 'Image']\n",
    "    print(f\"特徴点列数 / Keypoint columns: {len(keypoint_cols)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\n最初の5行 / First 5 rows:\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 欠損値分析 / Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Missing value analysis\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing_values,\n",
    "        'Missing Percentage': missing_percentage\n",
    "    })\n",
    "    \n",
    "    # Filter only columns with missing values\n",
    "    missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "    missing_df = missing_df.sort_values('Missing Percentage', ascending=False)\n",
    "    \n",
    "    print(\"欠損値分析 / Missing Value Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    if len(missing_df) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(len(missing_df)), missing_df['Missing Percentage'])\n",
    "        plt.xlabel('Keypoint Features')\n",
    "        plt.ylabel('Missing Percentage (%)')\n",
    "        plt.title('Missing Values by Keypoint Feature')\n",
    "        plt.xticks(range(len(missing_df)), missing_df.index, rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 画像データ分析 / Image Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Analyze image data\n",
    "    sample_image_str = df['Image'].iloc[0]\n",
    "    sample_pixels = np.array(sample_image_str.split(), dtype=np.float32)\n",
    "    \n",
    "    print(\"画像データ分析 / Image Data Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"画像ピクセル数 / Image pixels: {len(sample_pixels)}\")\n",
    "    print(f\"想定画像サイズ / Expected image size: {int(np.sqrt(len(sample_pixels)))}x{int(np.sqrt(len(sample_pixels)))}\")\n",
    "    print(f\"ピクセル値範囲 / Pixel value range: {sample_pixels.min():.1f} - {sample_pixels.max():.1f}\")\n",
    "    print(f\"ピクセル値平均 / Pixel value mean: {sample_pixels.mean():.1f}\")\n",
    "    print(f\"ピクセル値標準偏差 / Pixel value std: {sample_pixels.std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. サンプル画像の可視化 / Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Visualize sample images\n",
    "    num_samples = min(8, len(df))\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Get image\n",
    "        image_str = df['Image'].iloc[i]\n",
    "        image = np.array(image_str.split(), dtype=np.float32).reshape(96, 96)\n",
    "        \n",
    "        # Display image\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f'Sample {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('サンプル画像 / Sample Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 特徴点データ分析 / Keypoint Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Analyze keypoint data using the preprocessor\n",
    "    stats = DataPreprocessor.analyze_dataset(data_path)\n",
    "    \n",
    "    print(\"特徴点データ統計 / Keypoint Data Statistics\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"全特徴点を持つサンプル / Samples with all keypoints: {stats['samples_with_all_keypoints']}\")\n",
    "    print(f\"欠損データを持つサンプル / Samples with missing data: {stats['samples_with_missing_data']}\")\n",
    "    \n",
    "    # Display keypoint statistics for available data\n",
    "    print(\"\\n特徴点座標統計 / Keypoint Coordinate Statistics:\")\n",
    "    for i, (name, stat) in enumerate(list(stats['keypoint_statistics'].items())[:10]):  # Show first 10\n",
    "        print(f\"{name}: mean={stat['mean']:.2f}, std={stat['std']:.2f}, range=[{stat['min']:.1f}, {stat['max']:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 特徴点付き画像の可視化 / Keypoint Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Find samples with complete keypoints\n",
    "    complete_samples = df.dropna()\n",
    "    \n",
    "    if len(complete_samples) > 0:\n",
    "        print(f\"完全なデータを持つサンプル数 / Samples with complete data: {len(complete_samples)}\")\n",
    "        \n",
    "        # Visualize samples with keypoints\n",
    "        num_samples = min(4, len(complete_samples))\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(16, 4))\n",
    "        if num_samples == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Get image and keypoints\n",
    "            row = complete_samples.iloc[i]\n",
    "            image_str = row['Image']\n",
    "            image = np.array(image_str.split(), dtype=np.float32).reshape(96, 96)\n",
    "            \n",
    "            # Get keypoints\n",
    "            keypoint_cols = [col for col in df.columns if col != 'Image']\n",
    "            keypoints = row[keypoint_cols].values.reshape(-1, 2)\n",
    "            \n",
    "            # Plot\n",
    "            axes[i].imshow(image, cmap='gray')\n",
    "            axes[i].scatter(keypoints[:, 0], keypoints[:, 1], c='red', s=20, alpha=0.8)\n",
    "            axes[i].set_title(f'Sample {i+1} with Keypoints')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle('特徴点付きサンプル画像 / Sample Images with Keypoints', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"完全なデータを持つサンプルがありません / No samples with complete data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 特徴点分布の可視化 / Keypoint Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Create keypoint distribution plot\n",
    "    keypoint_cols = [col for col in df.columns if col != 'Image']\n",
    "    keypoint_data = df[keypoint_cols].values\n",
    "    \n",
    "    # Use the visualization utility\n",
    "    fig = visualize_data_distribution(\n",
    "        keypoint_data, \n",
    "        keypoint_names=keypoint_cols,\n",
    "        save_path=None\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. データ分割の検証 / Data Split Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Test data splitting\n",
    "    try:\n",
    "        train_df, val_df, test_df = DataPreprocessor.split_data(\n",
    "            data_path,\n",
    "            val_size=0.2,\n",
    "            test_size=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        print(\"データ分割結果 / Data Split Results\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"訓練データ / Training data: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "        print(f\"検証データ / Validation data: {len(val_df)} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "        print(f\"テストデータ / Test data: {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "        print(f\"合計 / Total: {len(train_df) + len(val_df) + len(test_df)} samples\")\n",
    "        \n",
    "        # Visualize split\n",
    "        labels = ['Train', 'Validation', 'Test']\n",
    "        sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "        colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('データ分割 / Data Split Distribution')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"データ分割エラー / Data split error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. まとめ / Summary\n",
    "\n",
    "このノートブックでは以下の分析を行いました：\n",
    "\n",
    "This notebook performed the following analyses:\n",
    "\n",
    "1. **データの基本情報 / Basic data information**\n",
    "2. **欠損値の分析 / Missing value analysis**\n",
    "3. **画像データの特性 / Image data characteristics**\n",
    "4. **特徴点データの統計 / Keypoint data statistics**\n",
    "5. **サンプル画像の可視化 / Sample image visualization**\n",
    "6. **特徴点分布の分析 / Keypoint distribution analysis**\n",
    "7. **データ分割の検証 / Data split validation**\n",
    "\n",
    "次のステップとして、モデル訓練用のデータローダーを作成し、実際の訓練を開始することができます。\n",
    "\n",
    "As next steps, you can create data loaders for model training and start the actual training process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}